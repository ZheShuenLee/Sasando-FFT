{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sasando Acoustic Replication Pipeline\n",
        "\n",
        "This notebook implements a comprehensive pipeline to replicate the authentic acoustic sound of the traditional sasando using an electric version.\n",
        "\n",
        "## Background\n",
        "The sasando is a traditional Indonesian string instrument where sound is produced by vibrating strings acoustically amplified through a hand-formed, dried lontar leaf resonator. This unique resonator naturally amplifies frequencies between **98 Hz and 1047 Hz**. Modern electric versions replace the resonator with a pickup and speaker, sacrificing acoustic quality for portability.\n",
        "\n",
        "## Pipeline Overview\n",
        "1. **Data Collection & Preprocessing** - Load and prepare acoustic and electric recordings\n",
        "2. **Feature Extraction** - Extract time, frequency, and advanced audio features\n",
        "3. **Resonator Characterization** - Analyze the acoustic sasando's frequency response\n",
        "4. **Transformation Design** - Design filters and EQ to match acoustic characteristics\n",
        "5. **Transformation Application** - Apply transformations to electric signal\n",
        "6. **Comparison & Validation** - Compute similarity metrics and visualize results\n",
        "7. **Output** - Save transformed signal and generate reports\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1: Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries loaded successfully!\n",
            "Librosa available: True\n",
            "Soundfile available: True\n"
          ]
        }
      ],
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from scipy.fft import rfft, rfftfreq, irfft\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Audio analysis libraries\n",
        "try:\n",
        "    import librosa\n",
        "    import librosa.display\n",
        "    LIBROSA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Warning: librosa not available. Some advanced features will be disabled.\")\n",
        "    LIBROSA_AVAILABLE = False\n",
        "\n",
        "# Audio I/O\n",
        "try:\n",
        "    import soundfile as sf\n",
        "    SOUNDFILE_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SOUNDFILE_AVAILABLE = False\n",
        "    print(\"Warning: soundfile not available. Using scipy.io.wavfile instead.\")\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n",
        "print(f\"Librosa available: {LIBROSA_AVAILABLE}\")\n",
        "print(f\"Soundfile available: {SOUNDFILE_AVAILABLE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2: Configuration Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration parameters set!\n"
          ]
        }
      ],
      "source": [
        "# File paths - UPDATE THESE WITH YOUR ACTUAL FILE PATHS\n",
        "ACOUSTIC_FILE = 'acoustic_sasando.wav'  # Path to acoustic sasando recording\n",
        "ELECTRIC_FILE = 'electric_sasando.wav'  # Path to electric sasando recording\n",
        "OUTPUT_FILE = 'transformed_electric_sasando.wav'  # Output file name\n",
        "\n",
        "# Sasando resonator characteristics\n",
        "RESONATOR_LOW_FREQ = 98   # Hz - Lower bound of resonator amplification\n",
        "RESONATOR_HIGH_FREQ = 1047  # Hz - Upper bound of resonator amplification\n",
        "\n",
        "# Analysis parameters\n",
        "SAMPLE_RATE = 44100  # Standard audio sample rate (Hz)\n",
        "FFT_SIZE = 2048      # FFT window size (power of 2)\n",
        "HOP_LENGTH = 512     # Hop length for spectrogram\n",
        "\n",
        "# Feature extraction parameters\n",
        "N_MFCC = 13          # Number of MFCC coefficients\n",
        "N_CHROMA = 12        # Number of chroma features\n",
        "\n",
        "# Visualization parameters\n",
        "MAX_FREQ_PLOT = 2000  # Maximum frequency for plots (Hz)\n",
        "TIME_SLICE_START = 1.0  # Start time for time slice analysis (seconds)\n",
        "TIME_SLICE_DURATION = 0.5  # Duration of time slice (seconds)\n",
        "\n",
        "print(\"Configuration parameters set!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 3: Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading functions defined!\n"
          ]
        }
      ],
      "source": [
        "def load_audio_file(file_path, target_sr=None):\n",
        "    \"\"\"\n",
        "    Load audio file (WAV or CSV format)\n",
        "    Returns: audio_data, sample_rate, time_array\n",
        "    \"\"\"\n",
        "    if file_path.endswith('.csv'):\n",
        "        # Load CSV file (time, amplitude format)\n",
        "        data = np.genfromtxt(file_path, delimiter=',')\n",
        "        time = data[:, 0]\n",
        "        amplitude = data[:, 1]\n",
        "        sample_rate = 1 / (time[1] - time[0])\n",
        "        \n",
        "    elif file_path.endswith('.wav'):\n",
        "        # Load WAV file\n",
        "        if SOUNDFILE_AVAILABLE:\n",
        "            audio_data, sample_rate = sf.read(file_path)\n",
        "        else:\n",
        "            sample_rate, audio_data = wavfile.read(file_path)\n",
        "        \n",
        "        # Convert to mono if stereo\n",
        "        if len(audio_data.shape) > 1:\n",
        "            amplitude = np.mean(audio_data, axis=1)\n",
        "        else:\n",
        "            amplitude = audio_data\n",
        "        \n",
        "        # Normalize to float32 if needed\n",
        "        if amplitude.dtype == np.int16:\n",
        "            amplitude = amplitude.astype(np.float32) / 32768.0\n",
        "        elif amplitude.dtype == np.int32:\n",
        "            amplitude = amplitude.astype(np.float32) / 2147483648.0\n",
        "        \n",
        "        time = np.arange(0, len(amplitude) / sample_rate, 1 / sample_rate)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {file_path}\")\n",
        "    \n",
        "    # Resample if target sample rate is specified\n",
        "    if target_sr is not None and sample_rate != target_sr:\n",
        "        if LIBROSA_AVAILABLE:\n",
        "            amplitude = librosa.resample(amplitude, orig_sr=sample_rate, target_sr=target_sr)\n",
        "            sample_rate = target_sr\n",
        "            time = np.arange(0, len(amplitude) / sample_rate, 1 / sample_rate)\n",
        "        else:\n",
        "            # Simple resampling using scipy\n",
        "            num_samples = int(len(amplitude) * target_sr / sample_rate)\n",
        "            amplitude = signal.resample(amplitude, num_samples)\n",
        "            sample_rate = target_sr\n",
        "            time = np.arange(0, len(amplitude) / sample_rate, 1 / sample_rate)\n",
        "    \n",
        "    return amplitude, sample_rate, time\n",
        "\n",
        "def normalize_audio(audio, method='peak'):\n",
        "    \"\"\"\n",
        "    Normalize audio signal\n",
        "    method: 'peak' (normalize to Â±1) or 'rms' (normalize RMS)\n",
        "    \"\"\"\n",
        "    if method == 'peak':\n",
        "        max_val = np.max(np.abs(audio))\n",
        "        if max_val > 0:\n",
        "            return audio / max_val\n",
        "        return audio\n",
        "    elif method == 'rms':\n",
        "        rms = np.sqrt(np.mean(audio**2))\n",
        "        if rms > 0:\n",
        "            return audio / rms\n",
        "        return audio\n",
        "    return audio\n",
        "\n",
        "print(\"Loading functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading acoustic sasando...\n"
          ]
        },
        {
          "ename": "LibsndfileError",
          "evalue": "Error opening 'acoustic_sasando.wav': System error.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mLibsndfileError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading acoustic sasando...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     acoustic_audio, acoustic_sr, acoustic_time = \u001b[43mload_audio_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mACOUSTIC_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSAMPLE_RATE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     acoustic_audio = normalize_audio(acoustic_audio, method=\u001b[33m'\u001b[39m\u001b[33mpeak\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAcoustic loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(acoustic_audio)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(acoustic_audio)/acoustic_sr\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macoustic_sr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Hz\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mload_audio_file\u001b[39m\u001b[34m(file_path, target_sr)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m file_path.endswith(\u001b[33m'\u001b[39m\u001b[33m.wav\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Load WAV file\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m SOUNDFILE_AVAILABLE:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         audio_data, sample_rate = \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     18\u001b[39m         sample_rate, audio_data = wavfile.read(file_path)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Sasando-FFT/venv/lib/python3.13/site-packages/soundfile.py:305\u001b[39m, in \u001b[36mread\u001b[39m\u001b[34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(file, frames=-\u001b[32m1\u001b[39m, start=\u001b[32m0\u001b[39m, stop=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[33m'\u001b[39m\u001b[33mfloat64\u001b[39m\u001b[33m'\u001b[39m, always_2d=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    220\u001b[39m          fill_value=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, samplerate=\u001b[38;5;28;01mNone\u001b[39;00m, channels=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    221\u001b[39m          \u001b[38;5;28mformat\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, subtype=\u001b[38;5;28;01mNone\u001b[39;00m, endian=\u001b[38;5;28;01mNone\u001b[39;00m, closefd=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    222\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Provide audio data from a sound file as NumPy array.\u001b[39;00m\n\u001b[32m    223\u001b[39m \n\u001b[32m    224\u001b[39m \u001b[33;03m    By default, the whole file is read from the beginning, but the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    303\u001b[39m \n\u001b[32m    304\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m                   \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    307\u001b[39m         frames = f._prepare_read(start, stop, frames)\n\u001b[32m    308\u001b[39m         data = f.read(frames, dtype, always_2d, fill_value, out)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Sasando-FFT/venv/lib/python3.13/site-packages/soundfile.py:690\u001b[39m, in \u001b[36mSoundFile.__init__\u001b[39m\u001b[34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m._bitrate_mode = bitrate_mode\n\u001b[32m    688\u001b[39m \u001b[38;5;28mself\u001b[39m._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[32m    689\u001b[39m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m \u001b[38;5;28mself\u001b[39m._file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode).issuperset(\u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n\u001b[32m    692\u001b[39m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[32m    693\u001b[39m     \u001b[38;5;28mself\u001b[39m.seek(\u001b[32m0\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Sasando-FFT/venv/lib/python3.13/site-packages/soundfile.py:1265\u001b[39m, in \u001b[36mSoundFile._open\u001b[39m\u001b[34m(self, file, mode_int, closefd)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_ptr == _ffi.NULL:\n\u001b[32m   1263\u001b[39m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[32m   1264\u001b[39m     err = _snd.sf_error(file_ptr)\n\u001b[32m-> \u001b[39m\u001b[32m1265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix=\u001b[33m\"\u001b[39m\u001b[33mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.name))\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode_int == _snd.SFM_WRITE:\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28mself\u001b[39m._info.frames = \u001b[32m0\u001b[39m\n",
            "\u001b[31mLibsndfileError\u001b[39m: Error opening 'acoustic_sasando.wav': System error."
          ]
        }
      ],
      "source": [
        "# Load acoustic sasando recording\n",
        "print(\"Loading acoustic sasando...\")\n",
        "try:\n",
        "    acoustic_audio, acoustic_sr, acoustic_time = load_audio_file(ACOUSTIC_FILE, target_sr=SAMPLE_RATE)\n",
        "    acoustic_audio = normalize_audio(acoustic_audio, method='peak')\n",
        "    print(f\"Acoustic loaded: {len(acoustic_audio)} samples, {len(acoustic_audio)/acoustic_sr:.2f} seconds, {acoustic_sr} Hz\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Warning: {ACOUSTIC_FILE} not found. Using synthetic data for demonstration.\")\n",
        "    # Generate synthetic acoustic-like signal for demonstration\n",
        "    duration = 2.0\n",
        "    t = np.linspace(0, duration, int(SAMPLE_RATE * duration))\n",
        "    acoustic_audio = np.sin(2 * np.pi * 440 * t) * np.exp(-t * 0.5)  # A4 note with decay\n",
        "    acoustic_audio += 0.3 * np.sin(2 * np.pi * 880 * t) * np.exp(-t * 0.5)  # Harmonic\n",
        "    acoustic_audio = normalize_audio(acoustic_audio)\n",
        "    acoustic_sr = SAMPLE_RATE\n",
        "    acoustic_time = t\n",
        "\n",
        "# Load electric sasando recording\n",
        "print(\"Loading electric sasando...\")\n",
        "try:\n",
        "    electric_audio, electric_sr, electric_time = load_audio_file(ELECTRIC_FILE, target_sr=SAMPLE_RATE)\n",
        "    electric_audio = normalize_audio(electric_audio, method='peak')\n",
        "    print(f\"Electric loaded: {len(electric_audio)} samples, {len(electric_audio)/electric_sr:.2f} seconds, {electric_sr} Hz\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Warning: {ELECTRIC_FILE} not found. Using synthetic data for demonstration.\")\n",
        "    # Generate synthetic electric-like signal (broader frequency range)\n",
        "    duration = 2.0\n",
        "    t = np.linspace(0, duration, int(SAMPLE_RATE * duration))\n",
        "    electric_audio = np.sin(2 * np.pi * 440 * t) * np.exp(-t * 0.3)\n",
        "    electric_audio += 0.5 * np.sin(2 * np.pi * 880 * t) * np.exp(-t * 0.3)\n",
        "    electric_audio += 0.2 * np.sin(2 * np.pi * 1320 * t) * np.exp(-t * 0.3)\n",
        "    electric_audio += 0.1 * np.sin(2 * np.pi * 2000 * t) * np.exp(-t * 0.3)  # Higher freq\n",
        "    electric_audio = normalize_audio(electric_audio)\n",
        "    electric_sr = SAMPLE_RATE\n",
        "    electric_time = t\n",
        "\n",
        "print(\"\\nAudio files loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 4: Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_time_domain_features(audio, sr):\n",
        "    \"\"\"Extract time domain features\"\"\"\n",
        "    features = {}\n",
        "    \n",
        "    # RMS Energy\n",
        "    features['rms'] = np.sqrt(np.mean(audio**2))\n",
        "    \n",
        "    # Zero Crossing Rate\n",
        "    zero_crossings = np.where(np.diff(np.signbit(audio)))[0]\n",
        "    features['zcr'] = len(zero_crossings) / (len(audio) / sr)\n",
        "    \n",
        "    # Energy\n",
        "    features['energy'] = np.sum(audio**2)\n",
        "    \n",
        "    return features\n",
        "\n",
        "def extract_frequency_domain_features(audio, sr, n_fft=2048):\n",
        "    \"\"\"Extract frequency domain features\"\"\"\n",
        "    features = {}\n",
        "    \n",
        "    # FFT\n",
        "    fft = rfft(audio, n=n_fft)\n",
        "    freqs = rfftfreq(len(audio), 1/sr)\n",
        "    magnitude = np.abs(fft)\n",
        "    \n",
        "    features['frequencies'] = freqs\n",
        "    features['magnitude'] = magnitude\n",
        "    features['power_spectrum'] = magnitude**2\n",
        "    \n",
        "    # Spectral centroid (brightness)\n",
        "    if np.sum(magnitude) > 0:\n",
        "        features['spectral_centroid'] = np.sum(freqs * magnitude) / np.sum(magnitude)\n",
        "    else:\n",
        "        features['spectral_centroid'] = 0\n",
        "    \n",
        "    # Spectral rolloff (85% energy)\n",
        "    cumsum = np.cumsum(magnitude)\n",
        "    total_energy = cumsum[-1]\n",
        "    if total_energy > 0:\n",
        "        rolloff_idx = np.where(cumsum >= 0.85 * total_energy)[0]\n",
        "        if len(rolloff_idx) > 0:\n",
        "            features['spectral_rolloff'] = freqs[rolloff_idx[0]]\n",
        "        else:\n",
        "            features['spectral_rolloff'] = freqs[-1]\n",
        "    else:\n",
        "        features['spectral_rolloff'] = 0\n",
        "    \n",
        "    # Spectral bandwidth\n",
        "    if features['spectral_centroid'] > 0 and np.sum(magnitude) > 0:\n",
        "        features['spectral_bandwidth'] = np.sqrt(\n",
        "            np.sum(((freqs - features['spectral_centroid'])**2) * magnitude) / np.sum(magnitude)\n",
        "        )\n",
        "    else:\n",
        "        features['spectral_bandwidth'] = 0\n",
        "    \n",
        "    return features\n",
        "\n",
        "def extract_advanced_features(audio, sr):\n",
        "    \"\"\"Extract advanced features using librosa if available\"\"\"\n",
        "    features = {}\n",
        "    \n",
        "    if LIBROSA_AVAILABLE:\n",
        "        # MFCCs (Mel-frequency cepstral coefficients)\n",
        "        features['mfcc'] = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=N_MFCC)\n",
        "        \n",
        "        # Chroma features\n",
        "        features['chroma'] = librosa.feature.chroma_stft(y=audio, sr=sr, n_chroma=N_CHROMA)\n",
        "        \n",
        "        # Spectral contrast\n",
        "        features['spectral_contrast'] = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
        "        \n",
        "        # Tonnetz (harmonic network)\n",
        "        features['tonnetz'] = librosa.feature.tonnetz(y=audio, sr=sr)\n",
        "        \n",
        "        # Harmonic and percussive components\n",
        "        features['harmonic'], features['percussive'] = librosa.effects.hpss(audio)\n",
        "    else:\n",
        "        print(\"Librosa not available. Advanced features skipped.\")\n",
        "    \n",
        "    return features\n",
        "\n",
        "print(\"Feature extraction functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features from acoustic sasando\n",
        "print(\"Extracting features from acoustic sasando...\")\n",
        "acoustic_time_features = extract_time_domain_features(acoustic_audio, acoustic_sr)\n",
        "acoustic_freq_features = extract_frequency_domain_features(acoustic_audio, acoustic_sr, n_fft=FFT_SIZE)\n",
        "acoustic_advanced_features = extract_advanced_features(acoustic_audio, acoustic_sr)\n",
        "\n",
        "print(f\"Acoustic features:\")\n",
        "print(f\"  RMS: {acoustic_time_features['rms']:.4f}\")\n",
        "print(f\"  ZCR: {acoustic_time_features['zcr']:.2f} Hz\")\n",
        "print(f\"  Spectral Centroid: {acoustic_freq_features['spectral_centroid']:.2f} Hz\")\n",
        "print(f\"  Spectral Rolloff: {acoustic_freq_features['spectral_rolloff']:.2f} Hz\")\n",
        "print(f\"  Spectral Bandwidth: {acoustic_freq_features['spectral_bandwidth']:.2f} Hz\")\n",
        "\n",
        "# Extract features from electric sasando\n",
        "print(\"\\nExtracting features from electric sasando...\")\n",
        "electric_time_features = extract_time_domain_features(electric_audio, electric_sr)\n",
        "electric_freq_features = extract_frequency_domain_features(electric_audio, electric_sr, n_fft=FFT_SIZE)\n",
        "electric_advanced_features = extract_advanced_features(electric_audio, electric_sr)\n",
        "\n",
        "print(f\"Electric features:\")\n",
        "print(f\"  RMS: {electric_time_features['rms']:.4f}\")\n",
        "print(f\"  ZCR: {electric_time_features['zcr']:.2f} Hz\")\n",
        "print(f\"  Spectral Centroid: {electric_freq_features['spectral_centroid']:.2f} Hz\")\n",
        "print(f\"  Spectral Rolloff: {electric_freq_features['spectral_rolloff']:.2f} Hz\")\n",
        "print(f\"  Spectral Bandwidth: {electric_freq_features['spectral_bandwidth']:.2f} Hz\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 5: Resonator Characterization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_resonator_response(audio, sr, low_freq, high_freq, n_fft=2048):\n",
        "    \"\"\"\n",
        "    Analyze the frequency response of the resonator\n",
        "    Returns frequency response within the resonator range\n",
        "    \"\"\"\n",
        "    # Compute frequency response\n",
        "    fft = rfft(audio, n=n_fft)\n",
        "    freqs = rfftfreq(len(audio), 1/sr)\n",
        "    magnitude = np.abs(fft)\n",
        "    \n",
        "    # Filter to resonator frequency range\n",
        "    mask = (freqs >= low_freq) & (freqs <= high_freq)\n",
        "    resonator_freqs = freqs[mask]\n",
        "    resonator_magnitude = magnitude[mask]\n",
        "    \n",
        "    # Normalize magnitude\n",
        "    if np.max(resonator_magnitude) > 0:\n",
        "        resonator_magnitude_norm = resonator_magnitude / np.max(resonator_magnitude)\n",
        "    else:\n",
        "        resonator_magnitude_norm = resonator_magnitude\n",
        "    \n",
        "    # Find dominant frequencies (peaks)\n",
        "    from scipy.signal import find_peaks\n",
        "    peaks, properties = find_peaks(resonator_magnitude_norm, height=0.1, distance=10)\n",
        "    peak_freqs = resonator_freqs[peaks]\n",
        "    peak_magnitudes = resonator_magnitude_norm[peaks]\n",
        "    \n",
        "    return {\n",
        "        'frequencies': resonator_freqs,\n",
        "        'magnitude': resonator_magnitude,\n",
        "        'magnitude_norm': resonator_magnitude_norm,\n",
        "        'peak_frequencies': peak_freqs,\n",
        "        'peak_magnitudes': peak_magnitudes,\n",
        "        'mean_gain': np.mean(resonator_magnitude_norm),\n",
        "        'max_gain': np.max(resonator_magnitude_norm)\n",
        "    }\n",
        "\n",
        "# Analyze acoustic resonator response\n",
        "print(\"Analyzing acoustic resonator response...\")\n",
        "acoustic_resonator = analyze_resonator_response(\n",
        "    acoustic_audio, acoustic_sr, \n",
        "    RESONATOR_LOW_FREQ, RESONATOR_HIGH_FREQ, \n",
        "    n_fft=FFT_SIZE\n",
        ")\n",
        "\n",
        "print(f\"Resonator frequency range: {RESONATOR_LOW_FREQ} - {RESONATOR_HIGH_FREQ} Hz\")\n",
        "print(f\"Mean gain in range: {acoustic_resonator['mean_gain']:.4f}\")\n",
        "print(f\"Max gain in range: {acoustic_resonator['max_gain']:.4f}\")\n",
        "print(f\"Number of peaks found: {len(acoustic_resonator['peak_frequencies'])}\")\n",
        "if len(acoustic_resonator['peak_frequencies']) > 0:\n",
        "    print(f\"Dominant frequencies: {acoustic_resonator['peak_frequencies'][:5]} Hz\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 6: Transformation Design\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def design_bandpass_filter(low_freq, high_freq, sr, order=4):\n",
        "    \"\"\"Design a bandpass filter for the resonator frequency range\"\"\"\n",
        "    nyquist = sr / 2\n",
        "    low = low_freq / nyquist\n",
        "    high = high_freq / nyquist\n",
        "    \n",
        "    # Ensure frequencies are within valid range\n",
        "    low = max(0.01, min(low, 0.99))\n",
        "    high = max(0.01, min(high, 0.99))\n",
        "    \n",
        "    b, a = signal.butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "def design_eq_curve(reference_freq_response, target_freq_response, freqs):\n",
        "    \"\"\"\n",
        "    Design an EQ curve to match target frequency response\n",
        "    Returns gain values for each frequency\n",
        "    \"\"\"\n",
        "    # Normalize both responses\n",
        "    ref_norm = reference_freq_response / (np.max(reference_freq_response) + 1e-10)\n",
        "    target_norm = target_freq_response / (np.max(target_freq_response) + 1e-10)\n",
        "    \n",
        "    # Calculate gain needed (in dB)\n",
        "    # Avoid division by zero\n",
        "    ref_norm = np.clip(ref_norm, 1e-10, None)\n",
        "    target_norm = np.clip(target_norm, 1e-10, None)\n",
        "    \n",
        "    gain_db = 20 * np.log10(target_norm / ref_norm)\n",
        "    \n",
        "    # Smooth the EQ curve to avoid artifacts\n",
        "    from scipy.ndimage import gaussian_filter1d\n",
        "    gain_db_smooth = gaussian_filter1d(gain_db, sigma=2)\n",
        "    \n",
        "    return gain_db_smooth, gain_db\n",
        "\n",
        "def apply_eq_curve(audio, sr, freqs, gain_db, n_fft=2048):\n",
        "    \"\"\"Apply EQ curve to audio signal\"\"\"\n",
        "    # Compute FFT\n",
        "    fft = rfft(audio, n=n_fft)\n",
        "    audio_freqs = rfftfreq(len(audio), 1/sr)\n",
        "    \n",
        "    # Interpolate gain curve to match audio frequencies\n",
        "    from scipy.interpolate import interp1d\n",
        "    gain_interp = interp1d(freqs, gain_db, kind='linear', \n",
        "                          bounds_error=False, fill_value=0)\n",
        "    gain_at_audio_freqs = gain_interp(audio_freqs)\n",
        "    \n",
        "    # Convert dB to linear gain\n",
        "    gain_linear = 10**(gain_at_audio_freqs / 20)\n",
        "    \n",
        "    # Apply gain\n",
        "    fft_eq = fft * gain_linear\n",
        "    \n",
        "    # Convert back to time domain\n",
        "    audio_eq = irfft(fft_eq, n=len(audio))\n",
        "    \n",
        "    return audio_eq\n",
        "\n",
        "print(\"Transformation design functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Design bandpass filter\n",
        "print(\"Designing bandpass filter...\")\n",
        "bp_b, bp_a = design_bandpass_filter(RESONATOR_LOW_FREQ, RESONATOR_HIGH_FREQ, electric_sr)\n",
        "print(f\"Bandpass filter: {RESONATOR_LOW_FREQ} - {RESONATOR_HIGH_FREQ} Hz\")\n",
        "\n",
        "# Design EQ curve based on acoustic resonator response\n",
        "print(\"\\nDesigning EQ curve...\")\n",
        "# Get electric frequency response in resonator range\n",
        "electric_resonator = analyze_resonator_response(\n",
        "    electric_audio, electric_sr,\n",
        "    RESONATOR_LOW_FREQ, RESONATOR_HIGH_FREQ,\n",
        "    n_fft=FFT_SIZE\n",
        ")\n",
        "\n",
        "# Design EQ to match acoustic response\n",
        "eq_gain_db, eq_gain_db_raw = design_eq_curve(\n",
        "    electric_resonator['magnitude'],\n",
        "    acoustic_resonator['magnitude'],\n",
        "    electric_resonator['frequencies']\n",
        ")\n",
        "\n",
        "print(f\"EQ curve designed. Gain range: {np.min(eq_gain_db):.2f} to {np.max(eq_gain_db):.2f} dB\")\n",
        "print(\"Transformation pipeline designed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 7: Transformation Application\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply transformations to electric signal\n",
        "print(\"Applying transformations to electric signal...\")\n",
        "\n",
        "# Step 1: Apply bandpass filter\n",
        "print(\"  Step 1: Applying bandpass filter...\")\n",
        "electric_filtered = signal.filtfilt(bp_b, bp_a, electric_audio)\n",
        "\n",
        "# Step 2: Apply EQ curve\n",
        "print(\"  Step 2: Applying EQ curve...\")\n",
        "electric_eq = apply_eq_curve(\n",
        "    electric_filtered, electric_sr,\n",
        "    electric_resonator['frequencies'],\n",
        "    eq_gain_db,\n",
        "    n_fft=FFT_SIZE\n",
        ")\n",
        "\n",
        "# Step 3: Normalize output\n",
        "print(\"  Step 3: Normalizing output...\")\n",
        "transformed_audio = normalize_audio(electric_eq, method='peak')\n",
        "\n",
        "print(\"Transformation complete!\")\n",
        "print(f\"Original RMS: {np.sqrt(np.mean(electric_audio**2)):.4f}\")\n",
        "print(f\"Transformed RMS: {np.sqrt(np.mean(transformed_audio**2)):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 8: Similarity Metrics Computation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_euclidean_distance(vec1, vec2):\n",
        "    \"\"\"Compute Euclidean distance between two vectors\"\"\"\n",
        "    # Ensure same length\n",
        "    min_len = min(len(vec1), len(vec2))\n",
        "    return np.sqrt(np.sum((vec1[:min_len] - vec2[:min_len])**2))\n",
        "\n",
        "def compute_cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Compute cosine similarity between two vectors\"\"\"\n",
        "    # Ensure same length\n",
        "    min_len = min(len(vec1), len(vec2))\n",
        "    v1 = vec1[:min_len]\n",
        "    v2 = vec2[:min_len]\n",
        "    \n",
        "    dot_product = np.dot(v1, v2)\n",
        "    norm1 = np.linalg.norm(v1)\n",
        "    norm2 = np.linalg.norm(v2)\n",
        "    \n",
        "    if norm1 == 0 or norm2 == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    return dot_product / (norm1 * norm2)\n",
        "\n",
        "def compute_mfcc_distance(mfcc1, mfcc2):\n",
        "    \"\"\"Compute distance between MFCC feature matrices\"\"\"\n",
        "    if not LIBROSA_AVAILABLE:\n",
        "        return None\n",
        "    \n",
        "    # Average over time dimension\n",
        "    mfcc1_mean = np.mean(mfcc1, axis=1)\n",
        "    mfcc2_mean = np.mean(mfcc2, axis=1)\n",
        "    \n",
        "    return compute_euclidean_distance(mfcc1_mean, mfcc2_mean)\n",
        "\n",
        "def compute_spectral_distance(freq_features1, freq_features2):\n",
        "    \"\"\"Compute spectral distance metrics\"\"\"\n",
        "    # Interpolate to common frequency grid\n",
        "    from scipy.interpolate import interp1d\n",
        "    \n",
        "    freqs1 = freq_features1['frequencies']\n",
        "    mag1 = freq_features1['magnitude']\n",
        "    freqs2 = freq_features2['frequencies']\n",
        "    mag2 = freq_features2['magnitude']\n",
        "    \n",
        "    # Common frequency range\n",
        "    min_freq = max(freqs1[0], freqs2[0])\n",
        "    max_freq = min(freqs1[-1], freqs2[-1])\n",
        "    common_freqs = np.linspace(min_freq, max_freq, 1000)\n",
        "    \n",
        "    # Interpolate\n",
        "    interp1 = interp1d(freqs1, mag1, kind='linear', bounds_error=False, fill_value=0)\n",
        "    interp2 = interp1d(freqs2, mag2, kind='linear', bounds_error=False, fill_value=0)\n",
        "    \n",
        "    mag1_interp = interp1(common_freqs)\n",
        "    mag2_interp = interp2(common_freqs)\n",
        "    \n",
        "    # Normalize\n",
        "    mag1_norm = mag1_interp / (np.max(mag1_interp) + 1e-10)\n",
        "    mag2_norm = mag2_interp / (np.max(mag2_interp) + 1e-10)\n",
        "    \n",
        "    # Compute metrics\n",
        "    euclidean = compute_euclidean_distance(mag1_norm, mag2_norm)\n",
        "    cosine = compute_cosine_similarity(mag1_norm, mag2_norm)\n",
        "    \n",
        "    return {\n",
        "        'euclidean_distance': euclidean,\n",
        "        'cosine_similarity': cosine\n",
        "    }\n",
        "\n",
        "print(\"Similarity metric functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features from transformed signal\n",
        "print(\"Extracting features from transformed signal...\")\n",
        "transformed_freq_features = extract_frequency_domain_features(transformed_audio, electric_sr, n_fft=FFT_SIZE)\n",
        "transformed_advanced_features = extract_advanced_features(transformed_audio, electric_sr)\n",
        "\n",
        "# Compute similarity metrics\n",
        "print(\"\\nComputing similarity metrics...\")\n",
        "\n",
        "# Spectral distance\n",
        "spectral_metrics = compute_spectral_distance(acoustic_freq_features, transformed_freq_features)\n",
        "print(f\"Spectral Euclidean Distance: {spectral_metrics['euclidean_distance']:.4f}\")\n",
        "print(f\"Spectral Cosine Similarity: {spectral_metrics['cosine_similarity']:.4f}\")\n",
        "\n",
        "# MFCC distance\n",
        "if LIBROSA_AVAILABLE and 'mfcc' in acoustic_advanced_features and 'mfcc' in transformed_advanced_features:\n",
        "    mfcc_dist = compute_mfcc_distance(\n",
        "        acoustic_advanced_features['mfcc'],\n",
        "        transformed_advanced_features['mfcc']\n",
        "    )\n",
        "    if mfcc_dist is not None:\n",
        "        print(f\"MFCC Distance: {mfcc_dist:.4f}\")\n",
        "\n",
        "# Compare with original electric\n",
        "print(\"\\nComparing with original electric signal:\")\n",
        "electric_spectral_metrics = compute_spectral_distance(acoustic_freq_features, electric_freq_features)\n",
        "print(f\"Original Electric - Spectral Euclidean Distance: {electric_spectral_metrics['euclidean_distance']:.4f}\")\n",
        "print(f\"Original Electric - Spectral Cosine Similarity: {electric_spectral_metrics['cosine_similarity']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 9: Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualization\n",
        "fig = plt.figure(figsize=(16, 12))\n",
        "\n",
        "# 1. Time domain waveforms\n",
        "ax1 = plt.subplot(3, 3, 1)\n",
        "time_slice = int(TIME_SLICE_START * acoustic_sr)\n",
        "time_slice_end = int((TIME_SLICE_START + TIME_SLICE_DURATION) * acoustic_sr)\n",
        "ax1.plot(acoustic_time[time_slice:time_slice_end], acoustic_audio[time_slice:time_slice_end], 'b-', label='Acoustic', alpha=0.7)\n",
        "ax1.plot(electric_time[time_slice:time_slice_end], electric_audio[time_slice:time_slice_end], 'r-', label='Electric (Original)', alpha=0.7)\n",
        "ax1.plot(electric_time[time_slice:time_slice_end], transformed_audio[time_slice:time_slice_end], 'g-', label='Electric (Transformed)', alpha=0.7)\n",
        "ax1.set_xlabel('Time (s)')\n",
        "ax1.set_ylabel('Amplitude')\n",
        "ax1.set_title('Time Domain Waveforms (Slice)')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Frequency response comparison\n",
        "ax2 = plt.subplot(3, 3, 2)\n",
        "mask = acoustic_freq_features['frequencies'] <= MAX_FREQ_PLOT\n",
        "ax2.plot(acoustic_freq_features['frequencies'][mask], acoustic_freq_features['magnitude'][mask], 'b-', label='Acoustic', alpha=0.7, linewidth=2)\n",
        "mask = electric_freq_features['frequencies'] <= MAX_FREQ_PLOT\n",
        "ax2.plot(electric_freq_features['frequencies'][mask], electric_freq_features['magnitude'][mask], 'r-', label='Electric (Original)', alpha=0.7)\n",
        "mask = transformed_freq_features['frequencies'] <= MAX_FREQ_PLOT\n",
        "ax2.plot(transformed_freq_features['frequencies'][mask], transformed_freq_features['magnitude'][mask], 'g-', label='Electric (Transformed)', alpha=0.7)\n",
        "ax2.axvspan(RESONATOR_LOW_FREQ, RESONATOR_HIGH_FREQ, alpha=0.2, color='yellow', label='Resonator Range')\n",
        "ax2.set_xlabel('Frequency (Hz)')\n",
        "ax2.set_ylabel('Magnitude')\n",
        "ax2.set_title('Frequency Response Comparison')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_xlim([0, MAX_FREQ_PLOT])\n",
        "\n",
        "# 3. Resonator frequency range detail\n",
        "ax3 = plt.subplot(3, 3, 3)\n",
        "ax3.plot(acoustic_resonator['frequencies'], acoustic_resonator['magnitude_norm'], 'b-', label='Acoustic', linewidth=2)\n",
        "ax3.plot(electric_resonator['frequencies'], electric_resonator['magnitude_norm'], 'r-', label='Electric (Original)', alpha=0.7)\n",
        "transformed_resonator = analyze_resonator_response(transformed_audio, electric_sr, RESONATOR_LOW_FREQ, RESONATOR_HIGH_FREQ, n_fft=FFT_SIZE)\n",
        "ax3.plot(transformed_resonator['frequencies'], transformed_resonator['magnitude_norm'], 'g-', label='Electric (Transformed)', alpha=0.7)\n",
        "ax3.set_xlabel('Frequency (Hz)')\n",
        "ax3.set_ylabel('Normalized Magnitude')\n",
        "ax3.set_title('Resonator Range (98-1047 Hz)')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. EQ Curve\n",
        "ax4 = plt.subplot(3, 3, 4)\n",
        "ax4.plot(electric_resonator['frequencies'], eq_gain_db, 'purple', linewidth=2)\n",
        "ax4.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
        "ax4.set_xlabel('Frequency (Hz)')\n",
        "ax4.set_ylabel('Gain (dB)')\n",
        "ax4.set_title('EQ Curve (Applied to Electric)')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Spectrograms - Acoustic\n",
        "ax5 = plt.subplot(3, 3, 5)\n",
        "freqs_ac, times_ac, Sx_ac = signal.spectrogram(acoustic_audio, fs=acoustic_sr, nperseg=1024, noverlap=512)\n",
        "mask_freq = freqs_ac <= MAX_FREQ_PLOT\n",
        "im5 = ax5.pcolormesh(times_ac, freqs_ac[mask_freq], 10 * np.log10(Sx_ac[mask_freq, :] + 1e-10), cmap='viridis', shading='auto')\n",
        "ax5.set_ylabel('Frequency (Hz)')\n",
        "ax5.set_xlabel('Time (s)')\n",
        "ax5.set_title('Acoustic Spectrogram')\n",
        "plt.colorbar(im5, ax=ax5, label='Power (dB)')\n",
        "\n",
        "# 6. Spectrograms - Electric Original\n",
        "ax6 = plt.subplot(3, 3, 6)\n",
        "freqs_el, times_el, Sx_el = signal.spectrogram(electric_audio, fs=electric_sr, nperseg=1024, noverlap=512)\n",
        "mask_freq = freqs_el <= MAX_FREQ_PLOT\n",
        "im6 = ax6.pcolormesh(times_el, freqs_el[mask_freq], 10 * np.log10(Sx_el[mask_freq, :] + 1e-10), cmap='viridis', shading='auto')\n",
        "ax6.set_ylabel('Frequency (Hz)')\n",
        "ax6.set_xlabel('Time (s)')\n",
        "ax6.set_title('Electric Original Spectrogram')\n",
        "plt.colorbar(im6, ax=ax6, label='Power (dB)')\n",
        "\n",
        "# 7. Spectrograms - Electric Transformed\n",
        "ax7 = plt.subplot(3, 3, 7)\n",
        "freqs_tr, times_tr, Sx_tr = signal.spectrogram(transformed_audio, fs=electric_sr, nperseg=1024, noverlap=512)\n",
        "mask_freq = freqs_tr <= MAX_FREQ_PLOT\n",
        "im7 = ax7.pcolormesh(times_tr, freqs_tr[mask_freq], 10 * np.log10(Sx_tr[mask_freq, :] + 1e-10), cmap='viridis', shading='auto')\n",
        "ax7.set_ylabel('Frequency (Hz)')\n",
        "ax7.set_xlabel('Time (s)')\n",
        "ax7.set_title('Electric Transformed Spectrogram')\n",
        "plt.colorbar(im7, ax=ax7, label='Power (dB)')\n",
        "\n",
        "# 8. Spectral features comparison\n",
        "ax8 = plt.subplot(3, 3, 8)\n",
        "features = ['Centroid', 'Rolloff', 'Bandwidth']\n",
        "acoustic_vals = [acoustic_freq_features['spectral_centroid'], \n",
        "                 acoustic_freq_features['spectral_rolloff'], \n",
        "                 acoustic_freq_features['spectral_bandwidth']]\n",
        "electric_vals = [electric_freq_features['spectral_centroid'], \n",
        "                electric_freq_features['spectral_rolloff'], \n",
        "                electric_freq_features['spectral_bandwidth']]\n",
        "transformed_vals = [transformed_freq_features['spectral_centroid'], \n",
        "                   transformed_freq_features['spectral_rolloff'], \n",
        "                   transformed_freq_features['spectral_bandwidth']]\n",
        "x = np.arange(len(features))\n",
        "width = 0.25\n",
        "ax8.bar(x - width, acoustic_vals, width, label='Acoustic', color='blue', alpha=0.7)\n",
        "ax8.bar(x, electric_vals, width, label='Electric (Original)', color='red', alpha=0.7)\n",
        "ax8.bar(x + width, transformed_vals, width, label='Electric (Transformed)', color='green', alpha=0.7)\n",
        "ax8.set_ylabel('Frequency (Hz)')\n",
        "ax8.set_title('Spectral Features Comparison')\n",
        "ax8.set_xticks(x)\n",
        "ax8.set_xticklabels(features)\n",
        "ax8.legend()\n",
        "ax8.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 9. Similarity metrics\n",
        "ax9 = plt.subplot(3, 3, 9)\n",
        "metrics_names = ['Euclidean\\nDistance', 'Cosine\\nSimilarity']\n",
        "original_metrics = [electric_spectral_metrics['euclidean_distance'], \n",
        "                    electric_spectral_metrics['cosine_similarity']]\n",
        "transformed_metrics = [spectral_metrics['euclidean_distance'], \n",
        "                      spectral_metrics['cosine_similarity']]\n",
        "x = np.arange(len(metrics_names))\n",
        "width = 0.35\n",
        "ax9.bar(x - width/2, original_metrics, width, label='Original Electric', color='red', alpha=0.7)\n",
        "ax9.bar(x + width/2, transformed_metrics, width, label='Transformed Electric', color='green', alpha=0.7)\n",
        "ax9.set_ylabel('Metric Value')\n",
        "ax9.set_title('Similarity Metrics vs Acoustic')\n",
        "ax9.set_xticks(x)\n",
        "ax9.set_xticklabels(metrics_names)\n",
        "ax9.legend()\n",
        "ax9.grid(True, alpha=0.3, axis='y')\n",
        "ax9.axhline(1.0, color='black', linestyle='--', alpha=0.5, label='Perfect Match')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('sasando_analysis_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualization complete! Saved as 'sasando_analysis_results.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save transformed audio\n",
        "print(f\"Saving transformed audio to {OUTPUT_FILE}...\")\n",
        "\n",
        "# Convert to int16 for WAV file\n",
        "transformed_audio_int16 = (transformed_audio * 32767).astype(np.int16)\n",
        "\n",
        "try:\n",
        "    if SOUNDFILE_AVAILABLE:\n",
        "        sf.write(OUTPUT_FILE, transformed_audio_int16, electric_sr)\n",
        "    else:\n",
        "        wavfile.write(OUTPUT_FILE, electric_sr, transformed_audio_int16)\n",
        "    print(f\"Successfully saved to {OUTPUT_FILE}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving file: {e}\")\n",
        "\n",
        "# Generate summary report\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANALYSIS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nResonator Frequency Range: {RESONATOR_LOW_FREQ} - {RESONATOR_HIGH_FREQ} Hz\")\n",
        "print(f\"\\nSimilarity Metrics (vs Acoustic):\")\n",
        "print(f\"  Transformed Electric:\")\n",
        "print(f\"    - Euclidean Distance: {spectral_metrics['euclidean_distance']:.4f}\")\n",
        "print(f\"    - Cosine Similarity: {spectral_metrics['cosine_similarity']:.4f}\")\n",
        "print(f\"  Original Electric:\")\n",
        "print(f\"    - Euclidean Distance: {electric_spectral_metrics['euclidean_distance']:.4f}\")\n",
        "print(f\"    - Cosine Similarity: {electric_spectral_metrics['cosine_similarity']:.4f}\")\n",
        "print(f\"\\nImprovement:\")\n",
        "euclidean_improvement = ((electric_spectral_metrics['euclidean_distance'] - spectral_metrics['euclidean_distance']) / \n",
        "                         electric_spectral_metrics['euclidean_distance'] * 100)\n",
        "cosine_improvement = ((spectral_metrics['cosine_similarity'] - electric_spectral_metrics['cosine_similarity']) / \n",
        "                     (1 - electric_spectral_metrics['cosine_similarity'] + 1e-10) * 100)\n",
        "print(f\"  - Euclidean Distance: {euclidean_improvement:.2f}% reduction (lower is better)\")\n",
        "print(f\"  - Cosine Similarity: {cosine_improvement:.2f}% improvement (higher is better)\")\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
